<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Change Camera Background</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation"></script>
    <style>
        body { margin: 0; overflow: hidden; display: flex; justify-content: center; align-items: center; height: 100vh; background: black; }
        video, canvas { position: absolute; width: 100vw; height: 100vh; object-fit: cover; }
        #video { display: none; } /* Hide raw camera feed */
        #backgroundSelect { position: absolute; top: 10px; left: 10px; padding: 10px; font-size: 16px; }
    </style>
</head>
<body>
    <select id="backgroundSelect">
        <option value="video">Video</option>
        <option value="image">Image</option>
        <option value="color">Solid Color</option>
    </select>
    
    <video id="video" autoplay playsinline></video> <!-- Live Camera -->
    <video id="backgroundVideo" loop autoplay muted>
        <source src="Option 2.mp4" type="video/mp4">
    </video>
    <img id="backgroundImage" src="background.jpg" style="display:none;">
    <canvas id="canvas"></canvas> <!-- Final Output -->

    <script>
        let selectedBackground = "video";

        document.getElementById('backgroundSelect').addEventListener('change', function() {
            selectedBackground = this.value;
        });

        async function startCamera() {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
            video.srcObject = stream;
            return new Promise((resolve) => video.onloadedmetadata = resolve);
        }

        async function setupSegmentation() {
            const segmentation = new SelfieSegmentation({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}` });
            segmentation.setOptions({ modelSelection: 1 });
            segmentation.onResults(onResults);
            await segmentation.initialize();
            return segmentation;
        }

        function onResults(results) {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            // Set background based on selection
            if (selectedBackground === "video") {
                ctx.drawImage(document.getElementById('backgroundVideo'), 0, 0, canvas.width, canvas.height);
            } else if (selectedBackground === "image") {
                ctx.drawImage(document.getElementById('backgroundImage'), 0, 0, canvas.width, canvas.height);
            } else if (selectedBackground === "color") {
                ctx.fillStyle = "blue"; // Change color here
                ctx.fillRect(0, 0, canvas.width, canvas.height);
            }

            // Apply segmentation mask (remove background)
            ctx.globalCompositeOperation = "destination-atop";
            ctx.drawImage(results.segmentationMask, 0, 0, canvas.width, canvas.height);

            // Draw user on top
            ctx.globalCompositeOperation = "source-in";
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            ctx.globalCompositeOperation = "source-over"; // Reset blend mode
        }

        async function runSegmentation() {
            await startCamera();
            const video = document.getElementById('video');
            const segmentation = await setupSegmentation();

            function processFrame() {
                segmentation.send({ image: video });
                requestAnimationFrame(processFrame);
            }

            processFrame();
        }

        runSegmentation();
    </script>
</body>
</html>
